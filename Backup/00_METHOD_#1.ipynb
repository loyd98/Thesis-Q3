{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %run COMBINED.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unwell Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwell = pd.read_excel(\"./00_unwell.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(mer, jerome, loyd):\n",
    "    li = [mer, jerome, loyd]\n",
    "    \n",
    "    def most_frequent(List): \n",
    "        counter = 0\n",
    "        num = List[0] \n",
    "\n",
    "        for i in List: \n",
    "            curr_frequency = List.count(i) \n",
    "            if(curr_frequency> counter): \n",
    "                counter = curr_frequency \n",
    "                num = i \n",
    "\n",
    "        return num\n",
    "    \n",
    "    return most_frequent(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwell[\"category\"] = unwell.apply(lambda x: filter(x.mer, x.jerome, x.loyd), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwell = unwell[unwell.category == \"unwell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df, column_name):\n",
    "    df['cleaned_text'] = df[column_name].fillna('')\n",
    "    df['cleaned_text'] = df['cleaned_text'].str.lower()\n",
    "    df['cleaned_text'] = df['cleaned_text'].str.replace(r'(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|rt|\\d+', '')\n",
    "    df['cleaned_text'] = df['cleaned_text'].str.replace(r'^\\s+|\\s+$', '') \n",
    "    df['cleaned_text'] = df['cleaned_text'].apply(lambda x: ' '.join([w for w in x.split() if w not in (stopwords)]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-50c449834fe5>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['cleaned_text'] = df['cleaned_text'].str.replace(r'(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|rt|\\d+', '')\n",
      "<ipython-input-31-50c449834fe5>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['cleaned_text'] = df['cleaned_text'].str.replace(r'^\\s+|\\s+$', '')\n"
     ]
    }
   ],
   "source": [
    "unwell = clean_text(unwell, \"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwell = unwell[[\"cleaned_text\", \"category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f abused different people young age</td>\n",
       "      <td>unwell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grew dad laying top woke staed continued close...</td>\n",
       "      <td>unwell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>would call mommy ask come wipe bathroom</td>\n",
       "      <td>unwell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>never anything said things stayed away</td>\n",
       "      <td>unwell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>seventh grade became depressed staed self harming</td>\n",
       "      <td>unwell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cleaned_text category\n",
       "5                 f abused different people young age   unwell\n",
       "6   grew dad laying top woke staed continued close...   unwell\n",
       "7             would call mommy ask come wipe bathroom   unwell\n",
       "9              never anything said things stayed away   unwell\n",
       "10  seventh grade became depressed staed self harming   unwell"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unwell.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "well = pd.read_csv(\"./00_cleaned_hm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "well = well[well.ground_truth_category.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "well[\"category\"] = well.ground_truth_category.apply(lambda x: \"well\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "well = well[0:len(unwell)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "well = well[[\"cleaned_hm\", \"category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "well = well.rename(columns={\"cleaned_hm\": \"cleaned_text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We had a serious talk with some friends of our...</td>\n",
       "      <td>well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I meditated last night.</td>\n",
       "      <td>well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>My grandmother start to walk from the bed afte...</td>\n",
       "      <td>well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I picked my daughter up from the airport and w...</td>\n",
       "      <td>well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>when i received flowers from my best friend</td>\n",
       "      <td>well</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cleaned_text category\n",
       "3   We had a serious talk with some friends of our...     well\n",
       "5                             I meditated last night.     well\n",
       "24  My grandmother start to walk from the bed afte...     well\n",
       "32  I picked my daughter up from the airport and w...     well\n",
       "42        when i received flowers from my best friend     well"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "well.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = unwell.append(well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unwell    2376\n",
       "well      2376\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4752"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4752"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4752"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"00_unwell_well_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(\"00_unwell_well_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f abused different people young age'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cleaned_text.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = model_selection.train_test_split(data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['cleaned_text']), tags=[r.category]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['cleaned_text']), tags=[r.category]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['ive', 'considered', 'cutting', 'declaring', 'independent', 'several', 'problems', 'theyre', 'paying', 'tuition', 'phone', 'plan'], tags=['unwell'])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tagged.values[69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3326/3326 [00:00<00:00, 1193757.92it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3326/3326 [00:00<00:00, 842254.13it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2192746.79it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2377344.09it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2493343.18it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2511749.21it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2515825.99it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2525390.13it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2533185.96it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2445268.20it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2512201.53it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2527678.04it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2353678.94it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2422339.83it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2469071.70it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2394482.51it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2431205.14it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2387924.53it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2319630.05it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2599749.37it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 1861026.56it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2409786.68it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2592020.64it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2347342.27it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2360449.26it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2344186.71it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2148506.87it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2493343.18it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 1978759.59it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2316163.89it/s]\n",
      "100%|██████████| 3326/3326 [00:00<00:00, 2272398.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import utils\n",
    "\n",
    "# %%time\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.7608695652173914\n",
      "Testing F1 score: 0.7608423987214106\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
    "\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train,y_train)\n",
    "\n",
    "y_pred = SVM.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      unwell       0.77      0.75      0.76       718\n",
      "        well       0.75      0.77      0.76       708\n",
      "\n",
      "    accuracy                           0.76      1426\n",
      "   macro avg       0.76      0.76      0.76      1426\n",
      "weighted avg       0.76      0.76      0.76      1426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(data['cleaned_text'], data['category'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "Y_train = Encoder.fit_transform(Y_train)\n",
    "Y_test = Encoder.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(data['cleaned_text'])\n",
    "X_train_tfidf = Tfidf_vect.transform(X_train)\n",
    "X_test_tfidf = Tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score:  98.87798036465638\n"
     ]
    }
   ],
   "source": [
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(X_train_tfidf, Y_train)\n",
    "\n",
    "predictions_NB = Naive.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Naive Bayes Accuracy Score: \", accuracy_score(predictions_NB, Y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       718\n",
      "           1       0.98      1.00      0.99       708\n",
      "\n",
      "    accuracy                           0.99      1426\n",
      "   macro avg       0.99      0.99      0.99      1426\n",
      "weighted avg       0.99      0.99      0.99      1426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, predictions_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score:  99.36886395511921\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(X_train_tfidf,Y_train)\n",
    "\n",
    "predictions_SVM = SVM.predict(X_test_tfidf)\n",
    "\n",
    "print(\"SVM Accuracy Score: \",accuracy_score(predictions_SVM, Y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       718\n",
      "           1       1.00      0.99      0.99       708\n",
      "\n",
      "    accuracy                           0.99      1426\n",
      "   macro avg       0.99      0.99      0.99      1426\n",
      "weighted avg       0.99      0.99      0.99      1426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, predictions_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_behaviors_string(string):\n",
    "    res = \"\"\n",
    "    \n",
    "    dic = get_behavior_breakdown(string)\n",
    "\n",
    "    \n",
    "    for key in dic:\n",
    "        arr = dic[key]\n",
    "        for i in arr:\n",
    "            res += i + \" \"\n",
    "        res += key + \" \"\n",
    "        \n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_behavior_breakdown' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-7fe8027d0baf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_behaviors_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I am not very sad and very angry.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-5a885ab0098a>\u001b[0m in \u001b[0;36mget_behaviors_string\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_behavior_breakdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_behavior_breakdown' is not defined"
     ]
    }
   ],
   "source": [
    "get_behaviors_string(\"I am not very sad and very angry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = get_sentiment_breakdown(\"I am not very sad and very angry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['negative',\n",
    "'positive',\n",
    "'fear',\n",
    "'anger',\n",
    "'trust',\n",
    "'sadness',\n",
    "'disgust',\n",
    "'anticip',\n",
    "'joy',\n",
    "'surprise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(dic, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
