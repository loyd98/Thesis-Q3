{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text manipulation\n",
    "\n",
    "Hello everyone! For this section, we will be learning how to manipulate text data using `TextBlob` and `Scikit-learn`. In particular, we will be using these packages to clean, format, and transform our text data into simpler text and vector representations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob as tb\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>handle</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1140836172530274304</td>\n",
       "      <td>ConnDiandra</td>\n",
       "      <td>2019-06-18 04:18:33</td>\n",
       "      <td>RT @SaraCarterDC: #TheSaraCarterShow: What's N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1140836171112747008</td>\n",
       "      <td>lillerik</td>\n",
       "      <td>2019-06-18 04:18:33</td>\n",
       "      <td>RT @viticci: Never seen this alert before – Ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1140836170051534848</td>\n",
       "      <td>bae_hon</td>\n",
       "      <td>2019-06-18 04:18:33</td>\n",
       "      <td>RT @Shazam: We love @OfficialMonstaX &amp;amp; @Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1140836169279631360</td>\n",
       "      <td>megandurazo</td>\n",
       "      <td>2019-06-18 04:18:33</td>\n",
       "      <td>RT @speriod: we need a new fiona apple album</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1140836169174749184</td>\n",
       "      <td>Nahirk</td>\n",
       "      <td>2019-06-18 04:18:33</td>\n",
       "      <td>RT @ij_baird: Help make FaceTime awesome, by a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id       handle           created_at  \\\n",
       "0  1140836172530274304  ConnDiandra  2019-06-18 04:18:33   \n",
       "1  1140836171112747008     lillerik  2019-06-18 04:18:33   \n",
       "2  1140836170051534848      bae_hon  2019-06-18 04:18:33   \n",
       "3  1140836169279631360  megandurazo  2019-06-18 04:18:33   \n",
       "4  1140836169174749184       Nahirk  2019-06-18 04:18:33   \n",
       "\n",
       "                                                text  \n",
       "0  RT @SaraCarterDC: #TheSaraCarterShow: What's N...  \n",
       "1  RT @viticci: Never seen this alert before – Ap...  \n",
       "2  RT @Shazam: We love @OfficialMonstaX &amp; @Fr...  \n",
       "3       RT @speriod: we need a new fiona apple album  \n",
       "4  RT @ij_baird: Help make FaceTime awesome, by a...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read our tweets from the previously created CSV\n",
    "tweets = pd.read_csv('out/tweets.csv', index_col=None, header=0)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text cleaning\n",
    "When cleaning our data, we want to remove unnecessary characters such as punctuations and whitespace. This is so that we can focus solely on the terms found in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweets):\n",
    "    \"\"\"\n",
    "    Replaces empty tweets, replaces text with lower case characters,\n",
    "    remove special characters and RTs, remove leading and trailing\n",
    "    whitespaces, and remove stopwords.\n",
    "    \"\"\"\n",
    "    tweets['cleaned_text'] = tweets['text'].fillna('')\n",
    "    tweets['cleaned_text'] = tweets['cleaned_text'].str.lower()\n",
    "    tweets['cleaned_text'] = tweets['cleaned_text'].str.replace(r'(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|rt|\\d+', '')\n",
    "    tweets['cleaned_text'] = tweets['cleaned_text'].str.replace(r'^\\s+|\\s+$', '') \n",
    "    tweets['cleaned_text'] = tweets['cleaned_text'].apply(lambda x: ' '.join([w for w in x.split() if w not in (stopwords)]))\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>handle</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1140836172530274304</td>\n",
       "      <td>ConnDiandra</td>\n",
       "      <td>2019-06-18 04:18:33</td>\n",
       "      <td>RT @SaraCarterDC: #TheSaraCarterShow: What's N...</td>\n",
       "      <td>thesaracaershow whats next russiainvestigation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1140836171112747008</td>\n",
       "      <td>lillerik</td>\n",
       "      <td>2019-06-18 04:18:33</td>\n",
       "      <td>RT @viticci: Never seen this alert before – Ap...</td>\n",
       "      <td>never seen ale apple tells app youre deleting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1140836170051534848</td>\n",
       "      <td>bae_hon</td>\n",
       "      <td>2019-06-18 04:18:33</td>\n",
       "      <td>RT @Shazam: We love @OfficialMonstaX &amp;amp; @Fr...</td>\n",
       "      <td>love amp whodoylove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1140836169279631360</td>\n",
       "      <td>megandurazo</td>\n",
       "      <td>2019-06-18 04:18:33</td>\n",
       "      <td>RT @speriod: we need a new fiona apple album</td>\n",
       "      <td>need new fiona apple album</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1140836169174749184</td>\n",
       "      <td>Nahirk</td>\n",
       "      <td>2019-06-18 04:18:33</td>\n",
       "      <td>RT @ij_baird: Help make FaceTime awesome, by a...</td>\n",
       "      <td>baird help make facetime awesome applying swee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id       handle           created_at  \\\n",
       "0  1140836172530274304  ConnDiandra  2019-06-18 04:18:33   \n",
       "1  1140836171112747008     lillerik  2019-06-18 04:18:33   \n",
       "2  1140836170051534848      bae_hon  2019-06-18 04:18:33   \n",
       "3  1140836169279631360  megandurazo  2019-06-18 04:18:33   \n",
       "4  1140836169174749184       Nahirk  2019-06-18 04:18:33   \n",
       "\n",
       "                                                text  \\\n",
       "0  RT @SaraCarterDC: #TheSaraCarterShow: What's N...   \n",
       "1  RT @viticci: Never seen this alert before – Ap...   \n",
       "2  RT @Shazam: We love @OfficialMonstaX &amp; @Fr...   \n",
       "3       RT @speriod: we need a new fiona apple album   \n",
       "4  RT @ij_baird: Help make FaceTime awesome, by a...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  thesaracaershow whats next russiainvestigation...  \n",
       "1  never seen ale apple tells app youre deleting ...  \n",
       "2                                love amp whodoylove  \n",
       "3                         need new fiona apple album  \n",
       "4  baird help make facetime awesome applying swee...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean tweets\n",
    "cleaned_tweets = clean_tweets(tweets)\n",
    "cleaned_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the cleaned tweets into CSV\n",
    "cleaned_tweets.to_csv('out/cleaned_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text representation\n",
    "We also want to be able to transform our data from terms into numerals where we can apply quantitative techniques.\n",
    "\n",
    "1. **Document-term matrix**: occurence of words across documents\n",
    "2. **N-gram matrix**: occurence of n-grams (phrases of n length) accross documents\n",
    "3. **TFIDF matrix**: term frequency adjusted by the rarity of the in documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_to_dtm(tweets):\n",
    "    tweets = tweets['cleaned_text']\n",
    "    vectorizer = CountVectorizer(max_features=2000)\n",
    "    dtm = vectorizer.fit_transform(tweets)\n",
    "    pickle.dump(vectorizer, open('out/dtm.pk', 'wb'))\n",
    "    return dtm, vectorizer\n",
    "\n",
    "def tweets_to_ngram(tweets, n=2):\n",
    "    tweets = tweets['cleaned_text']\n",
    "    vectorizer = CountVectorizer(\n",
    "        ngram_range=(n, n),\n",
    "        token_pattern=r'\\b\\w+\\b',\n",
    "        min_df=1,\n",
    "        max_features=2000)\n",
    "    dtm = vectorizer.fit_transform(tweets)\n",
    "    pickle.dump(vectorizer, open('out/ngram.pk', 'wb'))\n",
    "    return dtm, vectorizer\n",
    "\n",
    "def tweets_to_tfidf(tweets):\n",
    "    tweets = tweets['cleaned_text']\n",
    "    vectorizer = TfidfVectorizer(max_features=2000)\n",
    "    tfidf = vectorizer.fit_transform(tweets)\n",
    "    pickle.dump(vectorizer, open('out/tfidf.pk', 'wb'))\n",
    "    return tfidf, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM shape: (1000, 2000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('thesaracaershow', 1692),\n",
       " ('whats', 1908),\n",
       " ('next', 968),\n",
       " ('russiainvestigation', 1353),\n",
       " ('st', 1551)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get document-term matrix\n",
    "dtm, dtm_v = tweets_to_dtm(cleaned_tweets)\n",
    "print('DTM shape:', dtm.toarray().shape)\n",
    "list(dtm_v.vocabulary_.items())[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram matrix shape: (1000, 2000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('thesaracaershow whats', 1514),\n",
       " ('whats next', 1873),\n",
       " ('next russiainvestigation', 681),\n",
       " ('russiainvestigation st', 1218),\n",
       " ('st podcast', 1391)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get ngram matrix\n",
    "ngram, ngram_v = tweets_to_ngram(cleaned_tweets, n=2)\n",
    "print('Ngram matrix shape:', ngram.toarray().shape)\n",
    "list(ngram_v.vocabulary_.items())[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF matrix shape: (1000, 2000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('thesaracaershow', 1692),\n",
       " ('whats', 1908),\n",
       " ('next', 968),\n",
       " ('russiainvestigation', 1353),\n",
       " ('st', 1551)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get TFIDF matrix\n",
    "tfidf, tfidf_v = tweets_to_tfidf(cleaned_tweets)\n",
    "print('TFIDF matrix shape:', tfidf.toarray().shape)\n",
    "list(tfidf_v.vocabulary_.items())[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term frequencies\n",
    "We can convert our text metrices back into a list terms and their accompanying frequency.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_frequency(vector, vectorizer):\n",
    "    \"\"\"\n",
    "    Return a list of words and their corresponding occurence in the corpus\n",
    "    \"\"\"\n",
    "    total = vector.sum(axis=0)\n",
    "    frequency = [(w, total[0, i]) for w, i in vectorizer.vocabulary_.items()]\n",
    "    frequency = pd.DataFrame(frequency, columns=['term', 'frequency'])\n",
    "    frequency = frequency.sort_values(by='frequency', ascending=False).reset_index(drop=True)\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amp</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whodoylove</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>podcast</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term  frequency\n",
       "0       apple        319\n",
       "1         amp        209\n",
       "2        love        175\n",
       "3  whodoylove        163\n",
       "4     podcast         93"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dtm = vector_to_frequency(dtm, dtm_v)\n",
    "freq_dtm.to_csv('out/frequency_dtm.csv', index=False)\n",
    "freq_dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kirk show</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absolute madness</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phones sucks</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>need food</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>taco bell</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               term  frequency\n",
       "0         kirk show        162\n",
       "1  absolute madness        162\n",
       "2      phones sucks         67\n",
       "3         need food         67\n",
       "4         taco bell         67"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_ngram = vector_to_frequency(ngram, bigram_v)\n",
    "freq_ngram.to_csv('out/frequency_ngram.csv', index=False)\n",
    "freq_ngram.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>97.771467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whodoylove</td>\n",
       "      <td>97.085497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amp</td>\n",
       "      <td>95.662470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple</td>\n",
       "      <td>50.661257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>podcast</td>\n",
       "      <td>25.575891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term  frequency\n",
       "0        love  97.771467\n",
       "1  whodoylove  97.085497\n",
       "2         amp  95.662470\n",
       "3       apple  50.661257\n",
       "4     podcast  25.575891"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_tfidf = vector_to_frequency(tfidf, tfidf_v)\n",
    "freq_tfidf.to_csv('out/frequency_tfidf.csv', index=False)\n",
    "freq_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
